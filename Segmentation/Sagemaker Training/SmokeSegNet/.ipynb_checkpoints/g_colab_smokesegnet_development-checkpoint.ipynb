{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "smokesegnet_development.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f75029e72f3e492e9fbe9ca300b4271b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_10cd5a1392804768b2ba73a7a16e0049",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bef3fb947d614a42a1e54b59b847a335",
              "IPY_MODEL_c5d07e156cf842889e890dc8a3409c03"
            ]
          }
        },
        "10cd5a1392804768b2ba73a7a16e0049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bef3fb947d614a42a1e54b59b847a335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c19a493bfe8a40fea8af075195984cd5",
            "_dom_classes": [],
            "description": " 89%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 89,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b63f9ee13f04989933888a24b8fc270"
          }
        },
        "c5d07e156cf842889e890dc8a3409c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_91bd90be4a8a42b6bff8e3354aeec175",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 89/100 [36:15&lt;04:25, 24.14s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a123950c56b4945862706b4199cd727"
          }
        },
        "c19a493bfe8a40fea8af075195984cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b63f9ee13f04989933888a24b8fc270": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91bd90be4a8a42b6bff8e3354aeec175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a123950c56b4945862706b4199cd727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AepUtOEnlCkl"
      },
      "source": [
        "# Developing SmokeSegNet\n",
        "The aim of this notebook is to develop the code necassary to:\n",
        "* adapt model initialisation\n",
        "* adapt dataclass for dataloader\n",
        "* develop code for unzipping the tar file form of the data\n",
        "\n",
        "This notebook will also attempt to train the model for a small number of runs to observe model behaviour."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCGappofk9qE"
      },
      "source": [
        "#################### Imports #########################\n",
        "\n",
        "from __future__ import print_function, division\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "import time\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "# imports copied for loading in data\n",
        "import os\n",
        "import pandas as pd\n",
        "#from skimage import io, transform\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.ion()   # interactive mode\n",
        "multiGPU = False"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ovcvl67lFn4"
      },
      "source": [
        "############### Dataclass for Smoke Data ##################\n",
        "\n",
        "class SmokeDataset(Dataset):\n",
        "    def __init__(self, b03_dir, b04_dir, b05_dir, b06_dir, b07_dir, b09_dir, b11_dir, b12_dir, msk, pytorch=True): # b08 directory removed\n",
        "        super().__init__()\n",
        "        \n",
        "        # Loop through the files in red folder and combine, into a dictionary, the other bands\n",
        "        self.files = [self.combine_files(f, b04_dir, b05_dir, b06_dir, b07_dir, b09_dir, b11_dir, b12_dir, msk) for f in b03_dir.iterdir() if not f.is_dir()]\n",
        "        self.pytorch = pytorch\n",
        "        \n",
        "    def combine_files(self, r_file: Path, b04_dir, b05_dir, b06_dir, b07_dir, b09_dir, b11_dir, b12_dir, msk):\n",
        "        \n",
        "        files = {'b03': r_file,\n",
        "                'b04': b04_dir/r_file.name.replace('B03', 'B04'),\n",
        "                'b05': b05_dir/r_file.name.replace('B03', 'B05'),\n",
        "                'b06': b06_dir/r_file.name.replace('B03', 'B06'),\n",
        "                'b07': b07_dir/r_file.name.replace('B03', 'B07'),\n",
        "                #'b08': b08_dir/r_file.name.replace('B03', 'B08'),\n",
        "                'b09': b09_dir/r_file.name.replace('B03', 'B09'),\n",
        "                'b011': b11_dir/r_file.name.replace('B03', 'B11'),\n",
        "                'b012': b12_dir/r_file.name.replace('B03', 'B12'),\n",
        "                 'msk': msk/r_file.name.replace('B03', 'smokemask')\n",
        "                }\n",
        "\n",
        "        return files\n",
        "                                       \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.files)\n",
        "    \n",
        "    def open_as_array(self, idx, invert=False, include_nir=False):\n",
        "\n",
        "        img = np.stack([np.array(Image.open(self.files[idx]['b03'])),\n",
        "                            np.array(Image.open(self.files[idx]['b04'])),\n",
        "                            np.array(Image.open(self.files[idx]['b05'])),\n",
        "                        np.array(Image.open(self.files[idx]['b06'])),\n",
        "                        np.array(Image.open(self.files[idx]['b07'])),\n",
        "                        #np.array(Image.open(self.files[idx]['b08'])),\n",
        "                        np.array(Image.open(self.files[idx]['b09'])),\n",
        "                        np.array(Image.open(self.files[idx]['b011'])),\n",
        "                        np.array(Image.open(self.files[idx]['b012'])),\n",
        "                           ], axis=2)\n",
        "    \n",
        "    \n",
        "        if invert:\n",
        "            img = img.transpose((2,0,1))\n",
        "    \n",
        "        # normalize\n",
        "        return (img / np.iinfo(img.dtype).max)\n",
        "\n",
        "    def open_mask(self, idx, add_dims=False):\n",
        "        \n",
        "        raw_mask = np.array(Image.open(self.files[idx]['msk']))\n",
        "        raw_mask = np.where(raw_mask==255, 1, 0)\n",
        "        \n",
        "        return np.expand_dims(raw_mask, 0) if add_dims else raw_mask\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        x = torch.tensor(self.open_as_array(idx, invert=self.pytorch, include_nir=True), dtype=torch.float32)\n",
        "        y = torch.tensor(self.open_mask(idx, add_dims=False), dtype=torch.torch.int64)\n",
        "        \n",
        "        return x, y\n",
        "\n",
        "    \n",
        "    def __repr__(self):\n",
        "        s = 'Dataset class with {} files'.format(self.__len__())\n",
        "\n",
        "        return s"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn0t9xCTlHs2"
      },
      "source": [
        "############## Code for Unpacking Data ###############\n",
        "!tar -I pigz -xvf smokedata/SmokeDataset.tar -C smokedata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7qpziVHl_ow",
        "outputId": "ec6b6708-efe1-4233-adab-6a273dca176b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd '/content/drive/My Drive/Segmentation Model/SmokeSegDataset'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Segmentation Model/SmokeSegDataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi7BiS2rmJ93",
        "outputId": "b429b027-2fce-4beb-a66a-dfcabfa071ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mB01T55HGA_20191201T000241\u001b[0m/  \u001b[01;34mT56HKG_20191231T000241\u001b[0m/\n",
            "\u001b[01;34mT55HGA_20200130T000231\u001b[0m/     \u001b[01;34mtraining\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwjIjsJolINW",
        "outputId": "2396a007-020f-480e-ab16-875e9c97e10d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "############### Import Data ##################\n",
        "\n",
        "base_path = Path('training')\n",
        "data = SmokeDataset(base_path/'train_B03', \n",
        "                    base_path/'train_B04', \n",
        "                    base_path/'train_B05', \n",
        "                    base_path/'train_B06',\n",
        "                    base_path/'train_B07',\n",
        "                    #base_path/'train_B08',\n",
        "                    base_path/'train_B09',\n",
        "                    base_path/'train_B11',\n",
        "                    base_path/'train_B12',\n",
        "                    base_path/'train_smokemask')\n",
        "len(data)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2523"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udz3xhg_lITZ"
      },
      "source": [
        "############### Import Model ##################\n",
        "\n",
        "from segnet2 import SegNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDySOLaApJlr"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "class SegNet(nn.Module):\n",
        "    def __init__(self,input_nbr,label_nbr):\n",
        "        super(SegNet, self).__init__()\n",
        "\n",
        "        batchNorm_momentum = 0.1\n",
        "\n",
        "        self.conv11 = nn.Conv2d(input_nbr, 64, kernel_size=3, padding=1)\n",
        "        self.bn11 = nn.BatchNorm2d(64, momentum= batchNorm_momentum)\n",
        "        self.conv12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn12 = nn.BatchNorm2d(64, momentum= batchNorm_momentum)\n",
        "\n",
        "        self.conv21 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn21 = nn.BatchNorm2d(128, momentum= batchNorm_momentum)\n",
        "        self.conv22 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn22 = nn.BatchNorm2d(128, momentum= batchNorm_momentum)\n",
        "\n",
        "        self.conv31 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn31 = nn.BatchNorm2d(256, momentum= batchNorm_momentum)\n",
        "        self.conv32 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.bn32 = nn.BatchNorm2d(256, momentum= batchNorm_momentum)\n",
        "        self.conv33 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.bn33 = nn.BatchNorm2d(256, momentum= batchNorm_momentum)\n",
        "\n",
        "        self.conv41 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.bn41 = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
        "        self.conv42 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn42 = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
        "        self.conv43 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn43 = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
        "\n",
        "        self.conv51 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn51 = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
        "        self.conv52 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn52 = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
        "        self.conv53 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn53 = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
        "\n",
        "        self.conv53d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn53d = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
        "        self.conv52d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn52d = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
        "        self.conv51d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn51d = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
        "\n",
        "        self.conv43d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn43d = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
        "        self.conv42d = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn42d = nn.BatchNorm2d(512, momentum= batchNorm_momentum)\n",
        "        self.conv41d = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
        "        self.bn41d = nn.BatchNorm2d(256, momentum= batchNorm_momentum)\n",
        "\n",
        "        self.conv33d = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.bn33d = nn.BatchNorm2d(256, momentum= batchNorm_momentum)\n",
        "        self.conv32d = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.bn32d = nn.BatchNorm2d(256, momentum= batchNorm_momentum)\n",
        "        self.conv31d = nn.Conv2d(256,  128, kernel_size=3, padding=1)\n",
        "        self.bn31d = nn.BatchNorm2d(128, momentum= batchNorm_momentum)\n",
        "\n",
        "        self.conv22d = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn22d = nn.BatchNorm2d(128, momentum= batchNorm_momentum)\n",
        "        self.conv21d = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
        "        self.bn21d = nn.BatchNorm2d(64, momentum= batchNorm_momentum)\n",
        "\n",
        "        self.conv12d = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn12d = nn.BatchNorm2d(64, momentum= batchNorm_momentum)\n",
        "        self.conv11d = nn.Conv2d(64, label_nbr, kernel_size=3, padding=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Stage 1\n",
        "        x11 = F.relu(self.bn11(self.conv11(x)))\n",
        "        x12 = F.relu(self.bn12(self.conv12(x11)))\n",
        "        x1p, id1 = F.max_pool2d(x12,kernel_size=2, stride=2,return_indices=True)\n",
        "\n",
        "        # Stage 2\n",
        "        x21 = F.relu(self.bn21(self.conv21(x1p)))\n",
        "        x22 = F.relu(self.bn22(self.conv22(x21)))\n",
        "        x2p, id2 = F.max_pool2d(x22,kernel_size=2, stride=2,return_indices=True)\n",
        "\n",
        "        # Stage 3\n",
        "        x31 = F.relu(self.bn31(self.conv31(x2p)))\n",
        "        x32 = F.relu(self.bn32(self.conv32(x31)))\n",
        "        x33 = F.relu(self.bn33(self.conv33(x32)))\n",
        "        x3p, id3 = F.max_pool2d(x33,kernel_size=2, stride=2,return_indices=True)\n",
        "\n",
        "        # Stage 4\n",
        "        x41 = F.relu(self.bn41(self.conv41(x3p)))\n",
        "        x42 = F.relu(self.bn42(self.conv42(x41)))\n",
        "        x43 = F.relu(self.bn43(self.conv43(x42)))\n",
        "        x4p, id4 = F.max_pool2d(x43,kernel_size=2, stride=2,return_indices=True)\n",
        "\n",
        "        # Stage 5\n",
        "        x51 = F.relu(self.bn51(self.conv51(x4p)))\n",
        "        x52 = F.relu(self.bn52(self.conv52(x51)))\n",
        "        x53 = F.relu(self.bn53(self.conv53(x52)))\n",
        "        x5p, id5 = F.max_pool2d(x53,kernel_size=2, stride=2,return_indices=True)\n",
        "\n",
        "\n",
        "        # Stage 5d\n",
        "        x5d = F.max_unpool2d(x5p, id5, kernel_size=2, stride=2)\n",
        "        x53d = F.relu(self.bn53d(self.conv53d(x5d)))\n",
        "        x52d = F.relu(self.bn52d(self.conv52d(x53d)))\n",
        "        x51d = F.relu(self.bn51d(self.conv51d(x52d)))\n",
        "\n",
        "        # Stage 4d\n",
        "        x4d = F.max_unpool2d(x51d, id4, kernel_size=2, stride=2)\n",
        "        x43d = F.relu(self.bn43d(self.conv43d(x4d)))\n",
        "        x42d = F.relu(self.bn42d(self.conv42d(x43d)))\n",
        "        x41d = F.relu(self.bn41d(self.conv41d(x42d)))\n",
        "\n",
        "        # Stage 3d\n",
        "        x3d = F.max_unpool2d(x41d, id3, kernel_size=2, stride=2)\n",
        "        x33d = F.relu(self.bn33d(self.conv33d(x3d)))\n",
        "        x32d = F.relu(self.bn32d(self.conv32d(x33d)))\n",
        "        x31d = F.relu(self.bn31d(self.conv31d(x32d)))\n",
        "\n",
        "        # Stage 2d\n",
        "        x2d = F.max_unpool2d(x31d, id2, kernel_size=2, stride=2)\n",
        "        x22d = F.relu(self.bn22d(self.conv22d(x2d)))\n",
        "        x21d = F.relu(self.bn21d(self.conv21d(x22d)))\n",
        "\n",
        "        # Stage 1d\n",
        "        x1d = F.max_unpool2d(x21d, id1, kernel_size=2, stride=2)\n",
        "        x12d = F.relu(self.bn12d(self.conv12d(x1d)))\n",
        "        x11d = self.conv11d(x12d)\n",
        "\n",
        "        return x11d\n",
        "\n",
        "    def load_from_segnet(self, model_path):\n",
        "        s_dict = self.state_dict()# create a copy of the state dict\n",
        "        th = torch.load(model_path).state_dict() # load the weigths\n",
        "        # for name in th:\n",
        "            # s_dict[corresp_name[name]] = th[name]\n",
        "        self.load_state_dict(th)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWZJMg61sdo2",
        "outputId": "487c9c0b-56d7-421c-98d2-a22175d1b537",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mB01T55HGA_20191201T000241\u001b[0m/  \u001b[01;34mT56HKG_20191231T000241\u001b[0m/\n",
            "\u001b[01;34mT55HGA_20200130T000231\u001b[0m/     \u001b[01;34mtraining\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7_pZhpgsE0V"
      },
      "source": [
        "!cd '/content'"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwzFQRYKpZAO",
        "outputId": "4a8744df-ac57-4bc8-b5bc-8ad0b6209bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "####### Split the data ##########\n",
        "train_ds, valid_ds = torch.utils.data.random_split(data, (1766, 757)) # 70/30 train/val split\n",
        "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=4, shuffle=True)\n",
        "xb, yb = next(iter(train_dl))\n",
        "xb.shape, yb.shape"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 8, 384, 384]), torch.Size([4, 384, 384]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNu3CD3fuRj-",
        "outputId": "26952b2a-e93c-44fd-8d48-df6c2ffb9c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "xb, yb = next(iter(train_dl))\n",
        "xb.shape, yb.shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 8, 384, 384]), torch.Size([4, 384, 384]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs1hyNf1xkwq",
        "outputId": "5946f752-f8a9-4295-c5e5-745ebadbecbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "!pip install torch_lr_finder"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch_lr_finder\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/51/1a869067989a0fdaf18e49f0ee3aebfcb63470525245aac7dc390cfc676a/torch_lr_finder-0.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from torch_lr_finder) (1.6.0+cu101)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from torch_lr_finder) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch_lr_finder) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch_lr_finder) (4.41.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from torch_lr_finder) (3.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->torch_lr_finder) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->torch_lr_finder) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->torch_lr_finder) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch_lr_finder) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch_lr_finder) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch_lr_finder) (2.8.1)\n",
            "Installing collected packages: torch-lr-finder\n",
            "Successfully installed torch-lr-finder-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGDm5AldlSO1",
        "outputId": "85b757d1-8f45-475f-d7ff-4caddae15fbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385,
          "referenced_widgets": [
            "f75029e72f3e492e9fbe9ca300b4271b",
            "10cd5a1392804768b2ba73a7a16e0049",
            "bef3fb947d614a42a1e54b59b847a335",
            "c5d07e156cf842889e890dc8a3409c03",
            "c19a493bfe8a40fea8af075195984cd5",
            "0b63f9ee13f04989933888a24b8fc270",
            "91bd90be4a8a42b6bff8e3354aeec175",
            "4a123950c56b4945862706b4199cd727"
          ]
        }
      },
      "source": [
        "############# Find optimal learning rate #################\n",
        "\n",
        "from torch_lr_finder import LRFinder\n",
        "\n",
        "\n",
        "num_classes = 2          # smoke and non-smoke\n",
        "num_channels = 8         # 9 input channels for the hyperspectral image (-1) becuause of B08\n",
        "model = SegNet(num_channels,num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-7, weight_decay=1e-2)\n",
        "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
        "lr_finder.range_test(train_dl, end_lr=100, num_iter=100)\n",
        "lr_finder.plot() # to inspect the loss-learning rate graph\n",
        "lr_finder.reset() # to reset the model and optimizer to their initial state"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f75029e72f3e492e9fbe9ca300b4271b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Stopping early, the loss has diverged\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 1.52E-03\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwqOQldDyPxs"
      },
      "source": [
        "################## Train function ####################### w. saving every 500 steps \n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def train(model, train_dl, valid_dl, loss_fn, optimizer, scheduler, acc_fn, path, epochs=1):\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss, valid_loss = [], []\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train(True)  # Set trainind mode = true\n",
        "                dataloader = train_dl\n",
        "            else:\n",
        "                model.train(False)  # Set model to evaluate mode\n",
        "                dataloader = valid_dl\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_acc = 0.0\n",
        "\n",
        "            step = 0\n",
        "\n",
        "            # iterate over data\n",
        "            for x, y in dataloader:\n",
        "                x = x.cuda()\n",
        "                y = y.cuda()\n",
        "                step += 1\n",
        "\n",
        "                # forward pass\n",
        "                if phase == 'train':\n",
        "                    # zero the gradients\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(x)\n",
        "                    loss = loss_fn(outputs, y)\n",
        "\n",
        "                    # the backward pass frees the graph memory, so there is no \n",
        "                    # need for torch.no_grad in this training pass\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    scheduler.step()\n",
        "\n",
        "                else:\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model(x)\n",
        "                        loss = loss_fn(outputs, y.long())\n",
        "\n",
        "                # stats - whatever is the phase\n",
        "                acc = acc_fn(outputs, y)\n",
        "\n",
        "                running_acc  += acc*dataloader.batch_size\n",
        "                running_loss += loss*dataloader.batch_size \n",
        "\n",
        "                if step % 100 == 0:\n",
        "                    # clear_output(wait=True)\n",
        "                    print('Current step: {}  Loss: {}  Acc: {}  AllocMem (Mb): {}'.format(step, loss, acc, torch.cuda.memory_allocated()/1024/1024))\n",
        "                    # print(torch.cuda.memory_summary())\n",
        "                \n",
        "                # save the model every 500 steps in case the training quits unexpectedly\n",
        "                if step % 200 == 0:\n",
        "                  torch.save(model.state_dict(), path)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader.dataset)\n",
        "            epoch_acc = running_acc / len(dataloader.dataset)\n",
        "\n",
        "            clear_output(wait=True)\n",
        "            print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
        "            print('-' * 10)\n",
        "            print('{} Loss: {:.4f} Acc: {}'.format(phase, epoch_loss, epoch_acc))\n",
        "            print('-' * 10)\n",
        "\n",
        "            train_loss.append(epoch_loss) if phase=='train' else valid_loss.append(epoch_loss)\n",
        "\n",
        "    time_elapsed = time.time() - start\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n",
        "    \n",
        "    return train_loss, valid_loss    \n",
        "\n",
        "def acc_metric(predb, yb):\n",
        "    return (predb.argmax(dim=1) == yb.cuda()).float().mean()"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAlMsspXlIF-"
      },
      "source": [
        "################ Initialise Model ###############\n",
        "learning_rate = 1.52E-03 # learning rate from lr_finder\n",
        "num_classes = 2          # smoke and non-smoke\n",
        "num_channels = 8         # 9 input channels for the hyperspectral image but (-1) since B08 is incomplete\n",
        "model = SegNet(num_channels,num_classes)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)                  \n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "  print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
        "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
        "  model = nn.DataParallel(model)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjxGTpj_ytGg",
        "outputId": "56f7fe2d-c05b-4142-cfa8-3226259db3a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "path =  'smokesegnet_state_dict.pt'\n",
        "epochs = 20\n",
        "train_loss, valid_loss = train(model, train_dl, valid_dl, loss_fn, optimizer, exp_lr_scheduler, acc_metric, path, epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/19\n",
            "----------\n",
            "valid Loss: 0.0831 Acc: 1.0039629936218262\n",
            "----------\n",
            "Epoch 3/19\n",
            "----------\n",
            "Current step: 100  Loss: 0.10387706756591797  Acc: 1.0  AllocMem (Mb): 962.33642578125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8ooogoW7IDK"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(train_loss, label='Train loss')\n",
        "plt.plot(valid_loss, label='Valid loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6jZBMBqnr8r"
      },
      "source": [
        "# Conclusion\n",
        "Forming the necassary code for training the smokesegnet was successful. Unfortunately, the training was too slow on google colab. The training was cut early adn code transferred to Sagemaker for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2heOK5Rn6qY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}