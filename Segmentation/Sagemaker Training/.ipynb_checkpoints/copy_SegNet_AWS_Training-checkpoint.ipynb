{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Attempt at Training Script for SegNet \n",
    "* This notebook was used ot debug the first attempt\n",
    "* There were some delays for getting greater quotas\n",
    "* The training script was found to be the source of the problem\n",
    "* It has been re-organised and is functional for SegNet2\n",
    "* SegNet1 experienced some errors in the training jobs, and ther problem has not been resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Set Up ################\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "# ##yan - training on local instance to see what the problem is  \n",
    "# import boto3\n",
    "# import os\n",
    "# from sagemaker.local import LocalSession\n",
    "# from sagemaker.debugger import rule_configs, DebuggerHookConfig, CollectionConfig\n",
    "\n",
    "# sagemaker_session = LocalSession()\n",
    "# sagemaker_session.config = {'local': {'local_code': True}}\n",
    "# # Make sure to set this to your bucket and location\n",
    "# BUCKET_NAME = 'sagemaker-firefly-model-artifacts'\n",
    "# LOCATION_IN_BUCKET = 'smdebug_debug'\n",
    "\n",
    "# s3_bucket_for_tensors = 's3://{BUCKET_NAME}/{LOCATION_IN_BUCKET}'.format(BUCKET_NAME=BUCKET_NAME, LOCATION_IN_BUCKET=LOCATION_IN_BUCKET)\n",
    "# ##\n",
    "\n",
    "sagemaker_session = sagemaker.Session() #use for remote session\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "# prefix = 'sagemaker/DEMO-pytorch-mnist'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Path Set Up #################\n",
    "# speciy location of training data\n",
    "# train_data = 's3://sagemaker-firefly-model-data/Cloud Segmentation Data/38-Cloud_training'.format(bucket, prefix, 'train')\n",
    "train_data = 's3://sagemaker-firefly-model-data/Cloud Segmentation Data/38-Cloud_training'\n",
    "# train_data=\"file:///home/ec2-user/SageMaker/Dataset/CloudSeg/38-Cloud_training\"\n",
    "# validation_data = 's3://{}/{}/{}'.format(bucket, prefix, 'validation') currently training script does this split\n",
    "\n",
    "# specifiy location for model output to be saved\n",
    "# s3_output_location = 's3://sagemaker-firefly-model-artifacts'.format(bucket, prefix, 'xgboost_model_sdk')\n",
    "s3_output_location = 's3://sagemaker-firefly-model-artifacts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::067338613469:role/service-role/AmazonSageMaker-ExecutionRole-20200914T180083'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Initialise the PyTorch training estimator object ###########\n",
    "\n",
    "# train_instance_type='ml.c4.4xlarge'\n",
    "# estimator = PyTorch(entry_point='segnet2_train_script.py',\n",
    "#                     role=role,\n",
    "#                     framework_version='1.4.0',\n",
    "#                     train_instance_count=1,\n",
    "#                     train_instance_type='local',\n",
    "#                     output_path=s3_output_location,\n",
    "#                     hyperparameters={\n",
    "#                         'epochs': 5,\n",
    "#                         'learning_rate':0.001,\n",
    "#                         'batch-size':8\n",
    "#                     },\n",
    "#                     debugger_hook_config = DebuggerHookConfig(\n",
    "#                         s3_output_path=s3_bucket_for_tensors,  # Required\n",
    "#                         collection_configs=[\n",
    "#                             CollectionConfig(\n",
    "#                                 name=\"conv0_tensors\",\n",
    "#                                 parameters={\n",
    "#                                     \"include_regex\": \"*\",\n",
    "#                                     \"save_interval\": \"100\"\n",
    "#                                 }\n",
    "#                             )\n",
    "#                         ]\n",
    "#                     )\n",
    "#                    )\n",
    "estimator = PyTorch(entry_point='Refactored_segnet2_train_script.py',\n",
    "                    role=role,\n",
    "                    framework_version='1.4.0',\n",
    "                    train_instance_count=2,\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    output_path=s3_output_location,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'epochs': 5,\n",
    "                        'learning_rate':0.001,\n",
    "                        'backend': 'gloo',\n",
    "                        'batch_size':8\n",
    "                    }\n",
    "                   )\n",
    "# add train_use_spot_instances = True for spot training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "############## Run the training ################\n",
    "# estimator.fit({'train': train_data})\n",
    "estimator.fit({'train': train_data}, wait=False, logs='All') \n",
    "\n",
    "\\#job runs in background with wait=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying to get some debugging code in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_data(trial, tname, batch_index, steps_range, mode=modes.GLOBAL):\n",
    "    tensor = trial.tensor(tname)\n",
    "    vals = []\n",
    "    for s in steps_range:\n",
    "        val = tensor.value(step_num=s, mode=mode)[batch_index][0]\n",
    "        vals.append(val)\n",
    "    return vals\n",
    "\n",
    "def create_plots(steps_range):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(steps_range), constrained_layout=True, figsize=(2*len(steps_range), 2),\n",
    "                            subplot_kw={'xticks': [], 'yticks': []})\n",
    "    return fig, axs\n",
    "\n",
    "def plot_tensors(trial, layer, batch_index, steps_range):\n",
    "    if len(steps_range) > 0:    \n",
    "        fig, axs = create_plots(steps_range)\n",
    "        vals = get_data(trial, layer, batch_index, steps_range)\n",
    "\n",
    "        for ax, image, step in zip(axs.flat if isinstance(axs, np.ndarray) else np.array([axs]), vals, steps_range):\n",
    "            ax.imshow(image, cmap='gray')\n",
    "            ax.set_title(str(step))\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
