{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 Channel Segnet2\n",
    "* since the cloud data is only 4 channels, each channel will be element wise squared and square rooted in order to have an input tensor of depth 12\n",
    "* the point is to illustrate the operation of a 12 channel segmentaiton model\n",
    "* the reason for choosing 12 is that the hypersectral images have 12 channels, so this will provide the framework to train on the smoke data when it is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Imports #########################\n",
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "# imports copied for loading in data\n",
    "import os\n",
    "import pandas as pd\n",
    "#from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()   # interactive mode\n",
    "multiGPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############                  Import Model               ##################\n",
    "############### edit old data set to return 12 depth tensor ##################\n",
    "\n",
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, r_dir, g_dir, b_dir, nir_dir, gt_dir, pytorch=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Loop through the files in red folder and combine, into a dictionary, the other bands\n",
    "        self.files = [self.combine_files(f, g_dir, b_dir, nir_dir, gt_dir) for f in r_dir.iterdir() if not f.is_dir()]\n",
    "        self.pytorch = pytorch\n",
    "        \n",
    "    def combine_files(self, r_file: Path, g_dir, b_dir,nir_dir, gt_dir):\n",
    "        \n",
    "        files = {'red': r_file, \n",
    "                 'green':g_dir/r_file.name.replace('red', 'green'),\n",
    "                 'blue': b_dir/r_file.name.replace('red', 'blue'), \n",
    "                 'nir': nir_dir/r_file.name.replace('red', 'nir'),\n",
    "                 'gt': gt_dir/r_file.name.replace('red', 'gt')}\n",
    "\n",
    "        return files\n",
    "                                       \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.files)\n",
    "    \n",
    "    ##### here is where the model takes the images and turns them into a 3D numpy array\n",
    "    #####  - this is where the edit is to adapt to 12 channels\n",
    "     \n",
    "    def open_as_array(self, idx, invert=False, include_nir=False):\n",
    "\n",
    "        red = np.array(Image.open(self.files[idx]['red']))\n",
    "        red_squared = np.power(red, 2)\n",
    "        red_sqrt = np.power(red, 0.5)\n",
    "        green = np.array(Image.open(self.files[idx]['green']))\n",
    "        green_squared = np.power(green, 2)\n",
    "        green_sqrt = np.power(green, 0.5)\n",
    "        blue = np.array(Image.open(self.files[idx]['blue']))\n",
    "        blue_squared = np.power(blue, 2)\n",
    "        blue_sqrt = np.power(blue, 0.5)\n",
    "        nir = np.array(Image.open(self.files[idx]['nir']))\n",
    "        nir_squared = np.power(nir, 2)\n",
    "        nir_sqrt = np.power(nir, 0.5)\n",
    "        \n",
    "        hyperspectral_img = np.stack([red, \n",
    "                                      red_squared, \n",
    "                                      red_sqrt, \n",
    "                                      green, \n",
    "                                      green_squared, \n",
    "                                      green_sqrt, \n",
    "                                      blue, \n",
    "                                      blue_squared, \n",
    "                                      blue_sqrt, \n",
    "                                      nir, \n",
    "                                      nir_squared, \n",
    "                                      nir_sqrt], axis=2)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "        if invert:\n",
    "            hyperspectral_img = hyperspectral_img.transpose((2,0,1))\n",
    "    \n",
    "        # normalize\n",
    "        #return (hyperspectral_img / np.iinfo(hyperspectral_img.dtype).max)\n",
    "        # normalisation used for the 4 channel not working                                            #### TO FIX ####\n",
    "        \n",
    "        return hyperspectral_img\n",
    "\n",
    "    def open_mask(self, idx, add_dims=False):\n",
    "        \n",
    "        raw_mask = np.array(Image.open(self.files[idx]['gt']))\n",
    "        raw_mask = np.where(raw_mask==255, 1, 0)\n",
    "        \n",
    "        return np.expand_dims(raw_mask, 0) if add_dims else raw_mask\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = torch.tensor(self.open_as_array(idx, invert=self.pytorch, include_nir=True), dtype=torch.float32)\n",
    "        y = torch.tensor(self.open_mask(idx, add_dims=False), dtype=torch.torch.int64)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def open_as_array_image(self, idx, invert=False, include_nir=False):\n",
    "\n",
    "        raw_rgb = np.stack([np.array(Image.open(self.files[idx]['red'])),\n",
    "                            np.array(Image.open(self.files[idx]['green'])),\n",
    "                            np.array(Image.open(self.files[idx]['blue'])),\n",
    "                           ], axis=2)\n",
    "    \n",
    "        if include_nir:\n",
    "            nir = np.expand_dims(np.array(Image.open(self.files[idx]['nir'])), 2)\n",
    "            raw_rgb = np.concatenate([raw_rgb, nir], axis=2)\n",
    "    \n",
    "        if invert:\n",
    "            raw_rgb = raw_rgb.transpose((2,0,1))\n",
    "    \n",
    "        # normalize\n",
    "        return (raw_rgb / np.iinfo(raw_rgb.dtype).max)\n",
    "    \n",
    "    def open_as_pil(self, idx):\n",
    "        \n",
    "        arr = 256*self.open_as_array_image(idx)\n",
    "        \n",
    "        return Image.fromarray(arr.astype(np.uint8), 'RGB')\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = 'Dataset class with {} files'.format(self.__len__())\n",
    "\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Import Model ##################\n",
    "from segnet2 import SegNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8400"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### Import Data ##################\n",
    "base_path = Path('38-Cloud_training')\n",
    "data = CloudDataset(base_path/'train_red', \n",
    "                    base_path/'train_green', \n",
    "                    base_path/'train_blue', \n",
    "                    base_path/'train_nir',\n",
    "                    base_path/'train_gt')\n",
    "len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 12, 384, 384]), torch.Size([4, 384, 384]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### Data Loader ###############\n",
    "\n",
    "train_ds, valid_ds = torch.utils.data.random_split(data, (6000, 2400))\n",
    "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=4, shuffle=True)\n",
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Initialise Model ###############\n",
    "learning_rate = 1e-3     \n",
    "num_classes = 2          # assuming cloud and non cloud\n",
    "num_channels = 12        # 12 channels to be tested\n",
    "model = SegNet(num_channels,num_classes)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)                  \n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  model.cuda()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 384, 384])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing one pass\n",
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape, yb.shape\n",
    "pred = model(xb.cuda())\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Function Source\n",
    "https://www.kaggle.com/cordmaur/38-cloud-simple-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## train function \n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def train(model, train_dl, valid_dl, loss_fn, optimizer, scheduler, acc_fn, epochs=1):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss, valid_loss = [], []\n",
    "\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set trainind mode = true\n",
    "                dataloader = train_dl\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "                dataloader = valid_dl\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "\n",
    "            step = 0\n",
    "\n",
    "            # iterate over data\n",
    "            for x, y in dataloader:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "                step += 1\n",
    "\n",
    "                # forward pass\n",
    "                if phase == 'train':\n",
    "                    # zero the gradients\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(x)\n",
    "                    loss = loss_fn(outputs, y)\n",
    "\n",
    "                    # the backward pass frees the graph memory, so there is no \n",
    "                    # need for torch.no_grad in this training pass\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(x)\n",
    "                        loss = loss_fn(outputs, y.long())\n",
    "\n",
    "                # stats - whatever is the phase\n",
    "                acc = acc_fn(outputs, y)\n",
    "\n",
    "                running_acc  += acc*dataloader.batch_size\n",
    "                running_loss += loss*dataloader.batch_size \n",
    "\n",
    "                if step % 100 == 0:\n",
    "                    # clear_output(wait=True)\n",
    "                    print('Current step: {}  Loss: {}  Acc: {}  AllocMem (Mb): {}'.format(step, loss, acc, torch.cuda.memory_allocated()/1024/1024))\n",
    "                    # print(torch.cuda.memory_summary())\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_acc / len(dataloader.dataset)\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
    "            print('-' * 10)\n",
    "            print('{} Loss: {:.4f} Acc: {}'.format(phase, epoch_loss, epoch_acc))\n",
    "            print('-' * 10)\n",
    "\n",
    "            train_loss.append(epoch_loss) if phase=='train' else valid_loss.append(epoch_loss)\n",
    "\n",
    "    time_elapsed = time.time() - start\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n",
    "    \n",
    "    return train_loss, valid_loss    \n",
    "\n",
    "def acc_metric(predb, yb):\n",
    "    return (predb.argmax(dim=1) == yb.cuda()).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.1253 Acc: 0.9511369466781616\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#### training attempt 1\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_loss, valid_loss = train(model, train_dl, valid_dl, loss_fn, opt,exp_lr_scheduler, acc_metric, epochs=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Failure\n",
    "* the training was left to complete overnight, and during the 44th epoch, the kernal died unexpectedly\n",
    "* model saving has been implemented below to save the weights and entire model at the conclusion of training\n",
    "* this was done so since model saving had recently been introduced into practice\n",
    "\n",
    "## To do in the future\n",
    "* The model should be saved once an epochn future training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Save the model ######################\n",
    "\n",
    "# Specify a path\n",
    "PATH = 'Segmentation Model Artifacts/SegNet2_12_channel/SegNet2_state_dict_model_12_channel_1.pt'\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), PATH)     # saves the model wegiths\n",
    "\n",
    "\n",
    "\n",
    "PATH = 'Segmentation Model Artifacts/SegNet2_12_channel/SegNet2_12_channel_1.pt'\n",
    "\n",
    "torch.save(model, PATH)                  # saves the model weighs and model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(train_loss, label='Train loss')\n",
    "plt.plot(valid_loss, label='Valid loss')\n",
    "plt.legend()\n",
    "\n",
    "# save the loss plot information for future reference\n",
    "import pickle\n",
    "with open(\"segnet2_train_loss_12channel.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(train_loss, fp)\n",
    "\n",
    "with open(\"segnet2_valid_loss_12channel.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(valid_loss, fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m55"
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
