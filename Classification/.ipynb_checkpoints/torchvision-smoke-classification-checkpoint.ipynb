{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5wDKVNqMyJOf"
   },
   "source": [
    "# Torchvision CNN's for Smoke Classification\n",
    "In this notebook, torchvision models are adopted for smoke classification using the SmokeNet Dataset. Initial research brought VGG16, inception and resnet to our attention, so these models were focused on to begin with.\n",
    "\n",
    "The primary goal of this effort is to develop working knowledge with the Pytorch framework for machine learning and AI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zb_a919vIYhf"
   },
   "outputs": [],
   "source": [
    "#################### Imports #########################\n",
    "from __future__ import print_function, division\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import torch\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# interactive mode\n",
    "plt.ion()   \n",
    "multiGPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZo7VCEHJGV_"
   },
   "outputs": [],
   "source": [
    "################ Custom Data Class #####################\n",
    "\"\"\" \n",
    "The data set is composed of 1164 cloud images (class 1), 1009 dust (class 2), 1002 haze (class 3), 1027 land (class 4), \n",
    "1007 seaside (class 5), and 1016 smoke (class 0, the target.)\n",
    "\n",
    "The RGB images total to 6225 and are 256x256 with a resolution of 1km.\n",
    "\n",
    "The dataclass inherits from Pytroches Dataset class in order to form the necassary strucutre for using it with a\n",
    "dataloader.\n",
    "\"\"\"\n",
    "\n",
    "class SmokeNetDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations) # should be 6225 (ie. no. images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):                                                 \n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image_path = os.path.join(self.root_dir,\n",
    "                                self.annotations.iloc[idx, 0])   # get name of the image at idx\n",
    "        image = io.imread(image_path)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[idx, 1]))\n",
    "\n",
    "        if self.transform:\n",
    "          image = self.transform(image)\n",
    "        \n",
    "        return (image, y_label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QdxIRxg4e4Ri",
    "outputId": "d8d1aaa8-332b-40fc-ddaa-fcd2a6db4556"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/SmokeNet\n"
     ]
    }
   ],
   "source": [
    "# go to the data in google drive\n",
    "%cd '/content/drive/My Drive/SmokeNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1GTGW3k2bNKt"
   },
   "outputs": [],
   "source": [
    "################ Initialisation inlc. data processing #####################\n",
    "\n",
    "# hyperperameters\n",
    "num_classes = 6\n",
    "learning_rate = 1e-3\n",
    "batch_size = 32 \n",
    "num_epochs = 20\n",
    "\n",
    "# pack intended data augmentation transforms into a single object\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                             std=[0.5, 0.5, 0.5]) # SmokeNet used this\n",
    "    ])\n",
    "\n",
    "# load data from SmokeNet directory \n",
    "dataset = SmokeNetDataset(csv_file = 'SmokeNetData.csv', root_dir = 'SmokePics',\n",
    "                          transform = data_transform)\n",
    "\n",
    "# split the data into a  70/30 train/test split\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [4357, 1868])    \n",
    "\n",
    "# create the data loaders for both datasets\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# create dictionaries to contain both dataloaders \n",
    "dataloaders = {\"train\" : train_loader, \"val\" : test_loader}\n",
    "datasets = {\"train\": train_set, \"val\": test_set}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sgJBoEkGhU7O",
    "outputId": "a75f7ba6-a81c-4274-f74a-13e99762e5d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# define variables if GPU is to be used\n",
    "if torch.cuda.is_available():\n",
    "    use_gpu = True\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    use_gpu = False\n",
    "FloatTensor = torch.cuda.FloatTensor if use_gpu else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_gpu else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_gpu else torch.ByteTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_CvFb98n42t"
   },
   "outputs": [],
   "source": [
    "################ Function for Training the Model #####################\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    # initialise best weights as the random untrained ones\n",
    "    best_model_wts = model.state_dict()\n",
    "    # initialise best accuracy for comparing epochs and saving best weights\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:     \n",
    "            since_epoch = time.time()\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "    \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                inputs = Variable(inputs.type(Tensor))\n",
    "                labels = Variable(labels.type(LongTensor))\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                # statistics\n",
    "                running_loss += loss.data # changed from loss.data[0] because an error saying invalid index of 0-dim tensor\n",
    "                running_corrects += float(torch.sum(preds == labels.data))\n",
    "\n",
    "            epoch_loss = running_loss / len(datasets[phase])\n",
    "            epoch_acc = running_corrects / len(datasets[phase])\n",
    "\n",
    "            time_elapsed_epoch = time.time() - since_epoch\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} in {:.0f}m {:.0f}s'.format(\n",
    "                phase, epoch_loss, epoch_acc, time_elapsed_epoch // 60, time_elapsed_epoch % 60))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # keep the best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "colab_type": "code",
    "id": "j3sUtFHEoHXr",
    "outputId": "f8adbaf9-edb6-439e-9003-9b1e288dfc4e"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ab668a2fc5f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m################## Inception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0minception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minception_v3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0moptimizer_ft_inception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m                   \u001b[0;31m# using this becuase SmokeNet did\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mexp_lr_scheduler_inception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft_inception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/inception.py\u001b[0m in \u001b[0;36minception_v3\u001b[0;34m(pretrained, progress, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mInception3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/inception.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_classes, aux_logits, transform_input, inception_blocks, init_weights)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAuxLogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minception_aux\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMixed_7a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minception_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMixed_7b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minception_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1280\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMixed_7c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minception_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdaptiveAvgPool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/inception.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, conv_block)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranch3x3dbl_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m448\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranch3x3dbl_3a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranch3x3dbl_3b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranch_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m192\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/inception.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasicConv2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode)\u001b[0m\n\u001b[1;32m    406\u001b[0m         super(Conv2d, self).__init__(\n\u001b[1;32m    407\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             False, _pair(0), groups, bias, padding_mode)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[0;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "################# Initialse the models ########################\n",
    "\n",
    "\"\"\"\n",
    "# import the model from torchvision\n",
    "model = torchvision.models.googlenet(pretrainted=False)\n",
    "\"\"\"\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "################ Large Resnet\n",
    "resnet152 = models.resnet152(pretrained=False)\n",
    "num_ftrs = resnet152.fc.in_features\n",
    "resnet152.fc = nn.Linear(num_ftrs, 120)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(resnet152.parameters(), lr=learning_rate)                  \n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "################### smaller resnet\n",
    "resnet18 = models.resnet18(pretrained=False)\n",
    "optimizer_ft_18 = optim.Adam(resnet18.parameters(), lr=learning_rate)                  \n",
    "exp_lr_scheduler_18 = lr_scheduler.StepLR(optimizer_ft_18, step_size=7, gamma=0.1)\n",
    "\n",
    "################## Inception\n",
    "inception = models.inception_v3(pretrained=False)\n",
    "optimizer_ft_inception = optim.Adam(inception.parameters(), lr=learning_rate)                  \n",
    "exp_lr_scheduler_inception = lr_scheduler.StepLR(optimizer_ft_inception, step_size=7, gamma=0.1)\n",
    "\n",
    "################# Alexnet\n",
    "alexnet = models.alexnet(pretrained=False)\n",
    "optimizer_ft_alexnet = optim.Adam(alexnet.parameters(), lr=learning_rate)                  \n",
    "exp_lr_scheduler_alexnet = lr_scheduler.StepLR(optimizer_ft_alexnet, step_size=7, gamma=0.1)\n",
    "\n",
    "################# Vgg\n",
    "vgg16 = models.vgg16(pretrained=False)\n",
    "optimizer_ft_vgg16 = optim.Adam(vgg16.parameters(), lr=learning_rate)                   \n",
    "exp_lr_scheduler_vgg16 = lr_scheduler.StepLR(optimizer_ft_vgg16, step_size=7, gamma=0.1)\n",
    "\n",
    "################# Squeezenet\n",
    "squeezenet = models.squeezenet1_0(pretrained=False)\n",
    "optimizer_ft_squeezenet = optim.Adam(squeezenet.parameters(), lr=learning_rate)                  \n",
    "exp_lr_scheduler_squeezenet = lr_scheduler.StepLR(optimizer_ft_squeezenet, step_size=7, gamma=0.1)\n",
    "\n",
    "################# densenet\n",
    "densenet = models.densenet161(pretrained=False)\n",
    "optimizer_ft_densenet = optim.Adam(densenet.parameters(), lr=learning_rate)                  \n",
    "exp_lr_scheduler_densenet = lr_scheduler.StepLR(optimizer_ft_densenet, step_size=7, gamma=0.1)\n",
    "\n",
    "if torch.cuda.device_count() > 1 and multiGPU:\n",
    "  print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  resnet152 = nn.DataParallel(resnet152)\n",
    "  resnet18 = nn.DataParallel(resnet18)\n",
    "  inception = nn.DataParallel(inception)\n",
    "  alexnet = nn.DataParallel(alexnet)\n",
    "  vgg16 = nn.DataParallel(vgg16)\n",
    "  squeezenet = nn.DataParallel(squeezenet)\n",
    "  densenet = nn.DataParallel(densenet)\n",
    "\n",
    "if use_gpu:\n",
    "   resnet152.cuda()\n",
    "   resnet18.cuda()\n",
    "   inception.cuda()\n",
    "   alexnet.cuda()\n",
    "   vgg16.cuda()\n",
    "   squeezenet.cuda()\n",
    "   densenet.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EG4yinb0o6Qc"
   },
   "outputs": [],
   "source": [
    "####################### Train resnet152 ###########################\n",
    "\n",
    "resnet152 = train_model(resnet152, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                           num_epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7UwTn6WWlC7"
   },
   "outputs": [],
   "source": [
    "# re-initialise resnet 18\n",
    "resnet18 = models.resnet18(pretrained=False)\n",
    "optimizer_ft_18 = optim.Adam(resnet18.parameters(), lr=learning_rate)                   \n",
    "exp_lr_scheduler_18 = lr_scheduler.StepLR(optimizer_ft_18, step_size=7, gamma=0.1)\n",
    "\n",
    "if torch.cuda.device_count() > 1 and multiGPU:\n",
    "  print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  resnet18 = nn.DataParallel(resnet18)\n",
    "\n",
    "if use_gpu:\n",
    "   resnet18.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UwgihQX3_ob7"
   },
   "outputs": [],
   "source": [
    "####################### Train resnet18 ###########################\n",
    "\n",
    "resnet18 = train_model(resnet18, criterion, optimizer_ft_18, exp_lr_scheduler_18,\n",
    "                           num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "icz6aYVwxyR8"
   },
   "outputs": [],
   "source": [
    "####################### Train inception ###########################\n",
    "\n",
    "inception = train_model(inception, criterion, optimizer_ft_inception, exp_lr_scheduler_inception,\n",
    "                           num_epochs=1)\n",
    "\n",
    "#inception not working with training function\n",
    "########## ERROR: padding and the input size...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "338Scct0z4cB"
   },
   "outputs": [],
   "source": [
    "alexnet = train_model(alexnet, criterion, optimizer_ft_alexnet, exp_lr_scheduler_alexnet,\n",
    "                           num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9oDjckdGz4l_"
   },
   "outputs": [],
   "source": [
    "####################### Train vgg16 ###########################\n",
    "\n",
    "vgg16 = train_model(vgg16, criterion, optimizer_ft_vgg16, exp_lr_scheduler_vgg16,\n",
    "                           num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qPZQ4VFlz95J"
   },
   "outputs": [],
   "source": [
    "####################### Train squeezenet ###########################\n",
    "\n",
    "squeezenet = train_model(squeezenet, criterion, optimizer_ft_squeezenet, exp_lr_scheduler_squeezenet,\n",
    "                           num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YmH_vd85z971"
   },
   "outputs": [],
   "source": [
    "####################### Train densenet ###########################\n",
    "\n",
    "densenet = train_model(densenet, criterion, optimizer_ft_densenet, exp_lr_scheduler_densenet,\n",
    "                           num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zzCvHFa5ji04"
   },
   "outputs": [],
   "source": [
    "############### Initialise ResNet50 \n",
    "\n",
    "# try to see how resnet trains over more epochs, 18 seems to limit it\n",
    "\n",
    "resnet50 = models.resnet50(pretrained=False)\n",
    "optimizer_ft_50 = optim.Adam(resnet50.parameters(), lr=learning_rate)                   \n",
    "exp_lr_scheduler_50 = lr_scheduler.StepLR(optimizer_ft_50, step_size=7, gamma=0.1)\n",
    "\n",
    "if torch.cuda.device_count() > 1 and multiGPU:\n",
    "  print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  resnet50 = nn.DataParallel(resnet18)\n",
    "\n",
    "if use_gpu:\n",
    "   resnet50.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "77XClw3rj75v"
   },
   "outputs": [],
   "source": [
    "############### Train ResNet50 \n",
    "\n",
    "if torch.cuda.device_count() > 1 and multiGPU:\n",
    "  print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  resnet18 = nn.DataParallel(resnet18)\n",
    "\n",
    "if use_gpu:\n",
    "   resnet18.cuda()\n",
    "  \n",
    "resnet50 = train_model(resnet50, criterion, optimizer_ft_50, exp_lr_scheduler_50,\n",
    "                           num_epochs=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cj1KBT2q8KGS"
   },
   "source": [
    "# Model Inspection\n",
    "Having trained a number of models and developed a relative understanding of their performance, now the better models are inspected in more detail to see how they are operating.\n",
    "\n",
    "It was found that the models from torchvision were in a standard form equipped for the Imagenet datasets. This meant that:\n",
    "* The output layer was a fully connected layer with >>6 outputs\n",
    "* to make the prediction more accurate and model smaller, the final layer needed to be replaced with a linear layer with 6 outputs\n",
    "* to correctly do this, the model is inspected by printing it, and then the final layer is edited by name and replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxPsAKTN8GG_"
   },
   "outputs": [],
   "source": [
    "# print the model to observe the final layer\n",
    "print(resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnCzmVeH24lb"
   },
   "outputs": [],
   "source": [
    "# how to change the prediction layer\n",
    "resnet18.fc = nn.Linear(512, 6)\n",
    "\n",
    "# print the model to observe the change\n",
    "print(resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2DP7-lYz30Nn",
    "outputId": "ce9946e2-898f-4f7b-e814-d6ce7018ee26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.0419 Acc: 0.5033 in 0m 59s\n",
      "val Loss: 0.0695 Acc: 0.4406 in 13m 6s\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.0353 Acc: 0.5905 in 0m 59s\n",
      "val Loss: 0.0468 Acc: 0.4550 in 0m 22s\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.0332 Acc: 0.5990 in 0m 59s\n",
      "val Loss: 0.0385 Acc: 0.5375 in 0m 23s\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.0310 Acc: 0.6358 in 0m 59s\n",
      "val Loss: 0.0364 Acc: 0.6279 in 0m 22s\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.0311 Acc: 0.6312 in 0m 59s\n",
      "val Loss: 0.0324 Acc: 0.6440 in 0m 23s\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.0295 Acc: 0.6548 in 0m 59s\n",
      "val Loss: 0.0370 Acc: 0.5862 in 0m 23s\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.0263 Acc: 0.6982 in 0m 59s\n",
      "val Loss: 0.0229 Acc: 0.7388 in 0m 23s\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.0248 Acc: 0.7067 in 0m 60s\n",
      "val Loss: 0.0232 Acc: 0.7275 in 0m 23s\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.0242 Acc: 0.7090 in 0m 59s\n",
      "val Loss: 0.0221 Acc: 0.7398 in 0m 23s\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.0237 Acc: 0.7211 in 0m 59s\n",
      "val Loss: 0.0228 Acc: 0.7388 in 0m 23s\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.0241 Acc: 0.7193 in 0m 59s\n",
      "val Loss: 0.0224 Acc: 0.7382 in 0m 24s\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.0230 Acc: 0.7216 in 0m 58s\n",
      "val Loss: 0.0222 Acc: 0.7468 in 0m 22s\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0231 Acc: 0.7285 in 0m 59s\n",
      "val Loss: 0.0221 Acc: 0.7554 in 0m 23s\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.0230 Acc: 0.7351 in 0m 58s\n",
      "val Loss: 0.0209 Acc: 0.7719 in 0m 22s\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0221 Acc: 0.7411 in 0m 59s\n",
      "val Loss: 0.0202 Acc: 0.7655 in 0m 23s\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0227 Acc: 0.7367 in 1m 0s\n",
      "val Loss: 0.0211 Acc: 0.7687 in 0m 23s\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0223 Acc: 0.7448 in 0m 59s\n",
      "val Loss: 0.0200 Acc: 0.7618 in 0m 23s\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0216 Acc: 0.7471 in 0m 59s\n",
      "val Loss: 0.0196 Acc: 0.7714 in 0m 23s\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0220 Acc: 0.7393 in 0m 59s\n",
      "val Loss: 0.0196 Acc: 0.7762 in 0m 22s\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.0217 Acc: 0.7533 in 0m 59s\n",
      "val Loss: 0.0206 Acc: 0.7623 in 0m 23s\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.0217 Acc: 0.7519 in 0m 59s\n",
      "val Loss: 0.0197 Acc: 0.7709 in 0m 22s\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.0215 Acc: 0.7485 in 0m 58s\n",
      "val Loss: 0.0205 Acc: 0.7548 in 0m 22s\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.0220 Acc: 0.7496 in 0m 59s\n",
      "val Loss: 0.0204 Acc: 0.7612 in 0m 22s\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.0213 Acc: 0.7542 in 0m 58s\n",
      "val Loss: 0.0212 Acc: 0.7559 in 0m 22s\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0221 Acc: 0.7432 in 0m 59s\n",
      "val Loss: 0.0204 Acc: 0.7596 in 0m 22s\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.0215 Acc: 0.7528 in 0m 58s\n",
      "val Loss: 0.0203 Acc: 0.7634 in 0m 22s\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.0213 Acc: 0.7634 in 0m 60s\n",
      "val Loss: 0.0200 Acc: 0.7719 in 0m 23s\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.0220 Acc: 0.7482 in 0m 58s\n",
      "val Loss: 0.0201 Acc: 0.7661 in 0m 22s\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0221 Acc: 0.7432 in 0m 59s\n",
      "val Loss: 0.0198 Acc: 0.7794 in 0m 23s\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0217 Acc: 0.7468 in 0m 59s\n",
      "val Loss: 0.0204 Acc: 0.7570 in 0m 23s\n",
      "\n",
      "Training complete in 53m 30s\n",
      "Best val Acc: 0.779443\n"
     ]
    }
   ],
   "source": [
    "###### train the edited model with 6 outputs\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=False)\n",
    "resnet18.fc = nn.Linear(512, 6)\n",
    "optimizer_ft_18 = optim.Adam(resnet18.parameters(), lr=learning_rate)                  \n",
    "exp_lr_scheduler_18 = lr_scheduler.StepLR(optimizer_ft_18, step_size=7, gamma=0.1)\n",
    "\n",
    "if torch.cuda.device_count() > 1 and multiGPU:\n",
    "  print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  resnet18 = nn.DataParallel(resnet18)\n",
    "\n",
    "\n",
    "if use_gpu:\n",
    "   resnet18.cuda()\n",
    "resnet18 = train_model(resnet18, criterion, optimizer_ft_18, exp_lr_scheduler_18,\n",
    "                           num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2X01J4hW0-mt"
   },
   "outputs": [],
   "source": [
    "# try different loss criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "################## Inception\n",
    "inception = models.inception_v3(pretrained=False)\n",
    "optimizer_ft_inception = optim.Adam(inception.parameters(), lr=learning_rate)                   \n",
    "exp_lr_scheduler_inception = lr_scheduler.StepLR(optimizer_ft_inception, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "if torch.cuda.device_count() > 1 and multiGPU:\n",
    "  print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  inception = nn.DataParallel(inception)\n",
    "\n",
    "\n",
    "if use_gpu:\n",
    "   inception.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06tXbkGN1vA1"
   },
   "outputs": [],
   "source": [
    "####################### Train inception ###########################\n",
    "\n",
    "inception = train_model(inception, criterion, optimizer_ft_inception, exp_lr_scheduler_inception,\n",
    "                           num_epochs=1)\n",
    "\n",
    "#inception isn't liking this training function atm......\n",
    "########## ERROR: something to do with padding and the input size...."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RadNetBegins.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-4.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
